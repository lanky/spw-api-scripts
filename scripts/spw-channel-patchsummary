#!/usr/bin/env python
# -*- coding: utf-8 -*-
# RHN/Spacewalk API script
#
# requires the python-rhnapi module
# and python-progressbar
#
# Copyright (c) 2009-2012 Stuart Sears
#
# This file is part of spw-api-scripts
#
# spw-api-scripts is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free
# Software Foundation, either version 3 of the License, or (at your option)
# any later version.
#
# spw-api-scripts is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License
# for more details.
#
# You should have received a copy of the GNU General Public License along
# with spw-api-scripts. If not, see http://www.gnu.org/licenses/.
# template API script using the rhnapi python module
# the module will need to be on your PYTHONPATH
# or its parent directory added using sys.path.append
#
# ------------------------------- end licence -------------------------------- #
#


__doc__ = """
spw-channel-patchsummary

Designed to produce a list of unsynced errata from a source channel
since the given start date (defaults to the first of the current calendar month)
and produce a CVS output from them
Can read channel mappings from a JSON-format config file like this:
(only a single channel section shown below)
[
    {   "group"    : "clone-rhel5"
        "errata"   : "ALL",
        "base"   : "rhel-x86_64-server-5",
        "source"     : "clone-rhel-x86_64-server-5"
        "children" : [
            {
                "source" : "rhel-x86_64-server-productivity-5",
                "label"   : "clone-rhel-x86_64-server-productivity-5"
            },
            {
                "source" : "rhn-tools-rhel-x86_64-server-5",
                "label"   : "clone-rhn-tools-rhel-x86_64-server-5"
            }
        ]
    },
]
UPDATE:
    also reads YAML now, in this format
rhel5-group:
  label: clone-rhel-x86_64-server-5
  source: rhel-x86_64-server-5
  children:
    - label: clone-rhel-x86_64-server-productivity-5
      source: rhel-x86_64-server-productivity-5
    - label: clone-rhn-tools-rhel-x86_64-server-5
      source: rhn-tools-rhel-x86_64-server-5

"""
__author__ = "Stuart Sears <stuart@sjsears.com>"

# ------------------------- standard library imports ------------------------- #
import sys
import os
import time
import csv
# commandline option parsing
from optparse import OptionParser, OptionGroup
# for RPM version comparison (to find latest)
from rpmUtils.miscutils import compareEVR
# used to sort lists of errata dicts in print_report
from operator import itemgetter


try:
    import yaml
    yamlsupport = True
except ImportError:
    sys.stderr.write("YAML support not available\n")
    sys.stderr.write("Please install PyYAML if you require this\n")
    yamlsupport = False



# -------------------------- custom module imports --------------------------- #
import rhnapi
from rhnapi import channel
from rhnapi import errata
from rhnapi import utils
from progressbar import ProgressBar, Bar, Counter, Timer, Percentage

# ------------------------- configuration variables. ------------------------- #
# the defaults are probably okay, actually.
RHNCONFIG = '~/.rhninfo'
RHNHOST = 'localhost'

# put these in your configfile, dammit;
RHNUSER = None
RHNPASS = None

# defaults for channel mapping/grouping files.
CHANNELMAPS = [
                os.path.expanduser('~/.rhnapi/channels.yaml'),
                '/etc/sysconfig/rhnapi/channels.yaml',
              ]

ERRLEVELS = [ 'Critical', 'Important', 'Moderate', 'Low' ]

ERRTYPES = {
        'security' : 'Security Advisory',
        'bug'      : 'Bug Fix Advisory',
        'feature'  : 'Product Enhancement Advisory',
        }

# ---------------------------------------------------------------------------- #

def parse_cmdline(argv):
    """
    process the commandline :)
    """
    def error(errlines, usage=True, exitcode=1):
        """
        parser-specific error handling
        params:
        errlines(list)      - list (or tuple/set) of lines in error message
        exitcode(int)       - return code for exit statement.
        """
        if isinstance(errlines, list):
            sys.stderr.write("\n".join(errlines))
        else:
            sys.stderr.write("%s\n" % errlines)
        if usage:
            parser.print_help()
        sys.exit(exitcode)

    preamble = "Generate a CSV list of unsynced errata for a given channel since the given date"
    usagestr = "%prog [RHNOPTS]"
    # initialise our parser and set some default options
    parser = OptionParser(usage = usagestr, description = preamble)
    parser.add_option("--debug", action = "store_true", default = False,
        help = "enable debug output for RHN session (XMLRPC errors etc.) Sets loglevel to DEBUG.")
    parser.add_option('-v', '--verbose', action = 'store_true', default = False,
        help = "increase verbosity. Sets loglevel to INFO")
#    parser.add_option("-q", "--quiet", action = "store_true", default = False,
#        help = "Disable all logging and output")
    parser.add_option("-P", "--progress", action="store_true", default=False,
        help="Show a text progressbar for long-running operations")

    # RHN Satellite options group
    rhngrp = OptionGroup(parser, "RHN Satellite Options", "Defaults can be set in your RHN API config file (%s)" % RHNCONFIG )
    rhngrp.add_option("--server",help="RHN satellite server hostname [%default]", default=RHNHOST)
    rhngrp.add_option("--login", help="RHN login (username)" , default=RHNUSER)
    rhngrp.add_option("--pass", dest = "password", help="RHN password. This is better off in a config file.", default=RHNPASS)
    rhngrp.add_option("--config", dest = "config", help="Local RHN configuration file [ %default ]", default=RHNCONFIG)
    rhngrp.add_option("--cache", action = "store_true", default = False,
        help = "save usernames and password in config file, if missing")
    rhngrp.add_option("--log", dest = "logfile", default = None,
        help = "log output to the given filename. If you enable logging without this, logs go to stderr")
    parser.add_option_group(rhngrp)

    # script-specific options
    changrp = OptionGroup(parser, "Channel Selection Options")
    changrp.add_option("-c", "--channel", help = "cloned channel label to summarise")
    changrp.add_option("-s", "--source", help = "Source channel (where CHANNEL was cloned from")
    changrp.add_option("-m", "--channel-mapping",
        help = "JSON or YAML-format file grouping/mapping source and cloned channels", default = None)
    changrp.add_option("-g", "--group", help = "Channel group (from mapping file) to summarise")
    changrp.add_option("-l", "--list", action = "store_true", default = False,
        help = "display a list of channel mappings from the configuration file (and exit)")
    changrp.add_option("-i", "--info", action = "store_true", default = False,
        help = "display clone info about the chosen group and exit (requires -g/--group)")
    parser.add_option_group(changrp)

    errgrp = OptionGroup(parser, "Errata selection options")
    errgrp.add_option("-d", "--date", help = "Only summarise errata released after this date")
    errgrp.add_option("-e", "--end", help = "Only summarise errata released before this date")
    errgrp.add_option("--latest", action="store_true", default=False,
        help = "Only include the latest errata (based on synopsis and issue date)")
    errgrp.add_option("-t", "--type", default="security,bug,feature",
        help = "Errata types to show. 'security','bug','feature'. Can be a comma-separated list. No spaces")
    errgrp.add_option("-p", "--priority",
        help="""importance of errata to include. Comma-separated list, no spaces. Choose from 'critical',
'important','moderate', and 'low'. All levels are displayed by default""")
    parser.add_option_group(errgrp)

    outgrp = OptionGroup(parser, "Output selection")
    outgrp.add_option("-o", "--output", help="Output file for results in CSV format (prints to stdout if not specified and --report is not used)")
    outgrp.add_option("-j", "--json", help= "Dump errata information as JSON to the selected file")
    outgrp.add_option("--report", action="store_true", default=False,
        help="Pretty-print a report. Overrides CSV output to stdout (although -o still works)")
    parser.add_option_group(outgrp)

    if len(argv) == 0:
        parser.print_help()
        sys.exit(0)

    opts, args = parser.parse_args(argv)

    # check the args for errors etc...
    if opts.channel_mapping is not None:
        opts.channel_mapping = [ opts.channel_mapping ]
    else:
        opts.channel_mapping = CHANNELMAPS

    if opts.type:
        errtypes = opts.type.split(',')
        opts.errtypes = [ ERRTYPES.get(e) for e in errtypes if ERRTYPES.has_key(e) ]
    else:
        opts.errtypes = []

    if opts.priority:
        errprio = [ p.title() for p in opts.priority.split(',') ]
        opts.priorities = [ p for p in errprio if p in ERRLEVELS ]
    else:
        opts.priorities = []

    if opts.debug:
        opts.loglevel = 10
    elif opts.verbose:
        opts.loglevel = 20
    else:
        opts.loglevel = 30

    # if asked for a list of channel groups, no other args are required
    if opts.list:
        if not any(map(os.path.isfile, opts.channel_mapping)):
            error([ "ERROR: None of the specified or default config files exist",
                    "\n".join(opts.channel_mapping)], False, 3)
        else:
            return opts, args
    if not opts.group:
        if opts.info:
            error( "ERROR: The -i/--info option requires a group name (using -g/--group)", 2)

        if not opts.channel:
            error("ERROR: You must provide a channel to summarise", 2)

        if not opts.source:
            error( "ERROR: Which channel was %s cloned from?" % opts.channel, 2)

    # finally...
    return opts, args

# ---------------------------------------------------------------------------- #

def write_csv(data, filename, logger):
    """
    moved out of the main function for portability
    because we are munging the data a little, can't simply call utils.csvReport
    """
    # fields = ['advisory', 'synopsis', 'issue_date', 'last_modified_date', 'urgency' , 'channel', 'description']
    # fields = ['advisory', 'synopsis', 'issue_date', 'last_modified_date', 'urgency' , 'channel']
    fields = ['advisory', 'advisory_type', 'synopsis', 'issue_date', 'urgency' , 'destchannels']
    try:
        for row in data:
            syn = row['synopsis'].split(':')
            if len(syn) == 2:
                urg, desc = syn
            else:
                urg = 'None'
                desc = syn[0]
            row['urgency']  = urg.strip()
            row['synopsis'] = desc.strip()
            row['destchannels'] = '|'.join(row.get('channels'))

        if filename is not sys.stdout:
            sys.stderr.write("writing %d entries to %s\n" %(len(data), str(filename)))
        mywriter = utils.csvReport(data, filename, fields = fields)
        logger.info("wrote %d lines to %s" %(len(data), str(filename)))
        return mywriter

    except Exception, E:
        logger.warn("An Exception Occurred: %s" % E.__str__())
        logger.critical("ERROR: could not write to file %s" % filename)
        return False

# ---------------------------------------------------------------------------- #

def dump_group(channelmap, groupname, formatstr):
    """
    Just dumps information about an individual group from the mapping file
    """
    data = channelmap.get(groupname, None)
    if data is not None:
        print "Group : '%s'" % groupname
        print formatstr % {'label' : 'Channel Label', 'source' : 'Cloned From'}
        print formatstr % {'label' : '-------------', 'source' : '-----------'}
        print formatstr % data
        for c in data.get('children', []):
            print formatstr % c
        print


# ---------------------------------------------------------------------------- #

def dump_mappings(channelmaps, groupname=None):
    """
    Dump the list of channel mappings and groups to stdout
    parameters:
    channelmaps(dict)       - channel mapping dictionary (probably loaded from
                              JSON)
    """
    # utils.getMaxLen requires a list of dict, so:
    allvals = channelmaps.values()
    for d in channelmaps.values():
        allvals.extend(d['children'])
    maxlen = utils.getMaxLen(allvals)
    fmtstr = "%%(label)-%(label)ds %%(source)-%(source)ds" % maxlen
    if groupname is not None:
        if not channelmaps.has_key(groupname):
            sys.stderr.write("No config found for group %s\n" % groupname)
            return False
        else:
            dump_group(channelmaps, groupname, fmtstr)
    else:
        for group in sorted(channelmaps):
            dump_group(channelmaps, group, fmtstr)

# ---------------------------------------------------------------------------- #

def loadYAML(inputfile, logger):
    """
    Attempts to import data from the given YAML-format file
    """
    try:
        fd = open(inputfile, 'r')
        data = yaml.load(fd)
        fd.close()
        logger.info("Loaded YAML data from %s" % inputfile)
        return data
    except:
        logger.error("unable to load YAML data from %s" % inputfile)
        return None


# ---------------------- ERRATA PROCESSING BEGINS HERE ----------------------- #

def diff_errata(rhn, chanlist, date, end='', typelist=[], priolist=[], newest=False):
    """
    returns a dict of errata since the given date that have not been
    cloned from source to dest channels

    parameters:
    rhn(rhnapi.rhnSession)  - authenticated RHN session object
    chanlabel (str)         - channel label
    source(str)             - SOURCE channel label (usually where 'chanlabel' was cloned from)
    date(str)               - list errata since the given date fmt: YYYY-MM-DD HH:MM:SS
    newest(bool)            - whether to only consider the newest errata (based on synopsis)
    """
    # we'll generate an index of errata to apply in this,
    # { advisory : { errobj } }
    errindex = {}
    # we're now processing a list of channel mappings, with label and source keys
    # print chanlist
    if len(typelist) > 0:
        sys.stderr.write("  - Filtering on advisory types: %s\n" % ', '.join( typelist))
    if len(priolist) > 0:
        sys.stderr.write("  - Filtering on advisory priorities: %r\n" % ', '.join(priolist))
    for chanobj in chanlist:
        results = []
        chanlabel = chanobj.get('label')
        chansource = chanobj.get('source')
        sys.stderr.write("  - Processing errata for channel %(label)s (source: %(source)s)\n" % chanobj)
        # errata that are already in our channel:
        chanerrata = channel.listErrata(rhn, chanlabel)
        # this way we can compare keys AND synopses for accuracy
        # this gives us the YYYY:NNNN part of the erratum name (e.g. 2014:0015 )
        chanindex = dict(zip([ x['advisory'].split('-')[1] for x in chanerrata ], chanerrata))

        rhn.logInfo("Got %d errata in destination channel" % len(chanindex.keys()))
        # get a list of errata from thew source channel
        srcerrata = channel.listErrata(rhn, chansource, start_date = date, end_date = end)
        rhn.logInfo("Got %d errata in source channel %s" % (len(srcerrata), chansource))

        ## this is where we should do the payload comparisons

        # let's try and do only one pass over this list of dicts
        typecount = 0
        priocount = 0
        clonecount = 0

        # walk our list of potential errata
        for e in srcerrata:
            adv = e.get('advisory_name')
            if errindex.has_key(adv):
                # we've already processed this and have no need to do it again
                rhn.logDebug("skipping already processed erratum %(advisory_name)s" % e)
                # ensure it mentions our channel label
                errindex[adv]['channels'].append(chanlabel)
                continue
            else:
                # we haven't already seen and accepted this one
                rhn.logDebug("Processing %(advisory_name)s" % e)
                errkey = e['advisory'].split('-')[1]
                # extract the "priority" from the erratum synopsis
                prio = e.get('synopsis').split(':', 1)
                rhn.logDebug("priority: %s" % prio[0])
                if len(prio) > 1:
                    rhn.logDebug("adding 'priority' %s to erratum" % prio[0].strip())
                    # store the RH priority
                    e['priority'] = prio[0].strip()
                    # remove it from the 'synopsis' string
                    e['synopsis'] = prio[1].strip()
                else:
                    e['priority'] = "None"

                # remove errata that are not of the chosen type(s)
                if len(typelist) > 0 and e['advisory_type'].strip() not in typelist:
                    rhn.logDebug("removed %(advisory_name)s [%(advisory_type)s] according to --type selection" % e)
                    typecount += 1
                    continue
                # remove errata that don't match our priority list
                elif len(priolist) > 0 and e['priority'] not in priolist:
                    rhn.logDebug("removed %(advisory_name)s [%(priority)s] according to --priority selection" % e)
                    priocount += 1
                    continue
                # remove errata that have already been cloned
                # as they usually have the same YYYY:NNNN fields (e.g. RHBA-2013:0001 => CLA-2013:0001)
                elif errkey in chanindex.keys():
                    # double check on synopsis
                    if chanindex[errkey].get('synopsis').strip() == e.get('synopsis').strip():
                        rhn.logDebug("removed %(advisory_name)s [%(synopsis)s] due to index and synopsis match" % e)
                        clonecount += 1
                        continue
                else:
                    # we're keeping this one
                    # label the errata with its target channel
                    rhn.logDebug("keeping erratum %(advisory_name)s [%(advisory_type)s / %(priority)s]" % e)
                    results.append(e)
                    # add it to our index (this will replace any existing entries with this
                    e['channels'] = [ chanlabel ]
                    errindex[e.get('advisory')] = e

        # so far, we have removed
        # already-cloned errata
        if clonecount != 0:
            rhn.logInfo("removed %d already-cloned errata" % clonecount)
        # types we don't want
        if typecount != 0 :
            rhn.logInfo("removed %d errata by type selection" % typecount)
        # priorities we don't want
        if priocount != 0:
            rhn.logInfo("removed %d errata by priority selection" % priocount)

    removed = len(srcerrata) - len(results)
    rhn.logInfo("Removed %d errata, leaving %d to consider" %(removed, len(results)))

    sys.stderr.write("* %d unsynchronised errata to consider across %d channels\n" %(len(errindex.keys()), len(chanlist)))

    if newest:
        sys.stderr.write("* Reducing list to only latest applicable errata\n")
        sys.stderr.write("  - Doing simplistic reduction by synopsis and date: ")
        reduce_by_synopsis(errindex, rhn.logger)
        sys.stderr.write(" %d remaining\n" % len(errindex.keys()))
        rhn.logInfo("reduced list to %d errata by synopsis" % len(errindex.keys()))
        sys.stderr.write("* Reducing list of errata to latest only, by package comparison\n")
        reduce_by_payload(rhn, errindex)
        rhn.logInfo("reduced list to %d entries by package comparison" % len(errindex.keys()))
        sys.stderr.write("  - %d applicable errata remaining\n" % len(errindex.keys()))

    return errindex.values()


# ---------------------------------------------------------------------------- #
def reduce_by_synopsis(errdict, logger):
    """
    Find the newest (most recent, based on advisory name) erratum for each synopsis

    Edits the errdict object in place, so no return value
    """
    # need to get a list of the latest errata with a given synopsis based on date
    # errdict is a bit like this:
    # {
    #  'RHSA-2014:0310': {
    #                'advisory': 'RHSA-2014:0310',
    #                'advisory_name': 'RHSA-2014:0310',
    #                'advisory_synopsis': 'Critical: firefox security update',
    #                'advisory_type': 'Security Advisory',
    #                'date': '2014-03-18 04:00:00',
    #                'id': 9035,
    #                'issue_date': '2014-03-18 04:00:00',
    #                'last_modified_date': '2014-03-18 20:27:16',
    #                'synopsis': 'Critical: firefox security update',
    #                'update_date': '2014-03-18 04:00:00'},
    #                'channels' : [ chan1, chan2... ],
    #                'priority' : 'Critical',
    # ...
    # }

    # for keeping records of the 'latest' matching synopsis
    # e.g, based on the above example - we don't need the 'Critical' part
    # { 'firefox security update' : 'RHSA-2014:0310'}
    synindex = {}

    for adv, err in errdict.iteritems():
        # strip the priority off the 'synopsis', that's not used for comparison
        # A newer 'important' erratum will also contain the fixes from earlier 'critical' ones

        # this will result in a list, length 1 or 2 only
#        synsplit = err.get('synopsis').split(':', 1)
        # but we've already done this!
#         if len(synsplit) == 2:
#             err['priority'] = synsplit[0].strip()
#             syn = synsplit[1].strip()
#         else:
#             syn = synsplit[0].strip()
#             err['priority']  = "None"
#
        # name = err.get('advisory')
        syn = err.get('synopsis')

        if synindex.has_key(syn):
            curr = synindex[syn]
            logger.debug("Entry for synopsis '%s' already exists [%s]. Comparing values." % (syn, curr))

            if advisory_is_newer(adv, curr):
                logger.debug("%s is newer than %s" %(adv, curr))
                synindex[syn] = adv
            else:
                logger.debug("%s is not newer than %s. Continuing" %(adv, curr))
                continue
        else:
            logger.debug("adding %s [%s] to index" %(syn, adv))
            synindex[syn] = adv

        # print synindex

    for adv in errdict.keys():
        if adv not in synindex.values():
            del errdict[adv]

# ---------------------------------------------------------------------------- #

def reduce_by_payload(rhn, errindex):
    """
    processes a list of errata, comparing their packagelists to find the newest ones.

    Parameters:
        rhn (rhnapi.rhnSession): authenticated RHN session object
        errdict (dict of dict): indexed dictionary of errata objects

    Returns:
        list of dict, one per remaining erratum, including package information
    """
    if len(errindex.keys()) == 0:
        rhn.logDebug("no errata to consider, nothing to do")
        return errindex
    # get an index of the erratalist, by advisory name
    # we're now passing this in as a parameter
    # errindex = dict(zip([e.get('advisory_name') for e in errlist], errlist))
    # for indexing on latest packages
    pkgindex = {}

    rhn.logInfo("Processing errata payloads to get latest packages")
    rhn.logInfo("%d errata to consider" % len(errindex))

    sys.stderr.write("Processing packages for %d errata. This may be a slow process\n" % len(errindex))

    widgets = [ "Processing ", Counter(), " Errata" "[",Percentage(),"]", Bar(), Timer() ]
    pbar = ProgressBar(widgets=widgets, maxval=len(errindex), term_width=80).start()
    for idx, erratum in enumerate(errindex.keys()):
        # returns a list of dictionaries
        rhn.logDebug("processing %s" % erratum)
        pkglist = errata.listPackages(rhn, erratum)
        # just for giggles, let's remember our packagelist for future reference
        chanpkgs = {}
        # compare each package dict against our index
        for p in pkglist:
            for ch in p.get('providing_channels'):
                if chanpkgs.has_key(ch):
                    chanpkgs[ch].append(p.get('file'))
                else:
                    chanpkgs[ch] = [ p.get('file') ]
            namearch = "%(name)s.%(arch_label)s" % p
            # construct an EVR for comparison purposes
            evr = ( p.get('epoch').strip(), p.get('version'), p.get('release'))
            # see if we already have a record for this package

            # what we'll store if the current pkg is newer:
            pkgrec =  { 'evr' : evr, 'file': p.get('file'), 'erratum' : erratum }

            # get any existing record for this namearch pair
            cur = pkgindex.get(namearch)
            if cur is None:
                update = True
            else:
                update = compareEVR(evr, cur.get('evr')) > 0

            if update:
                if cur is None:
                    rhn.logDebug("%s (%s) not present in index, adding it" %(p.get('file'), erratum))
                else:
                    rhn.logDebug("%s (%s) > %s (%s), replacing it." %(p.get('file'), erratum, cur.get('file'), cur.get('erratum')))
                pkgindex[namearch] = pkgrec
            else:
                continue

            # update the progressbar
            pbar.update(idx + 1)

            errindex[erratum]['chanpkgs'] = chanpkgs

    print
    # now we need to extract all the goodness from our index
    errnames = set([p.get('erratum') for p in pkgindex.values()])
    utils.dumpJSON(pkgindex, '/tmp/pkgindex.json')
    for err in errindex.keys():
        if err not in errnames:
            del errindex[err]

    rhn.logInfo("Reduced errata list to %d entries by package comparison" % len(errnames))

# ---------------------------------------------------------------------------- #

def advisory_is_newer(advisory1, advisory2):
    """
    Simply splits up normal advisory strings and returns the newest one
    This does proper integer comparisons on the numerical parts
    returns True if advisory1 is newer, False if otherwise
    """
    # pull relevant info out of advisory names
    val1 = advisory1.split('-')[1]
    yr1, n1 = map(int, val1.split(':'))
    # and the second one too
    val2 = advisory2.split('-')[1]
    yr2, n2 = map (int, val2.split(':'))

    if yr1 < yr2:
        return False
    elif yr1 > yr2 :
        return True
    else:
        if n1 > n2:
            return True
        else:
            return False
    # we should never get here
    sys.stderr.write("eeek. Out of cheese error!\n")
    return False


# ---------------------------------------------------------------------------- #

def print_report(data, chanlist):
    """
    pretty-prints a report of our results, easier to parse for humans than CSV

    Parameters:
        data (list of dict):
            list of dictionary objects, each representing an erratum and the packages
            it affects, categorised by channel.
    """
    # the keys we are likely to care about
    # (* indicates a custom key, put there by the script)
    # advisory / advisory_name
    # synopsis / advisory_synopsis
    # *chanpkgs: map from SOURCE channels to provided packages
    # *priority: (security errata only: Critical/Important...), others: "None"

    # first, let's map our chanlist to a simple dictionary
    chandict = {}
    # this simply means we get a dict as follows:
    # { 'rhel-x86_64-server-6' : 'my-clone-name', 'rhel-...' for our group }
    for chan in chanlist:
        source = chan.get('source')
        label = chan.get('label')
        chandict[source] = label

    # output:
    # Erratum Type Priority Synopsis Affected channels (package count)
    # ======= ==== ======== ======== =================================

    # so, we need a format str for each erratum
    # basic format.

    maxlen = utils.getMaxLen(data)
    if data[0].has_key('chanpkgs'):
        fmtstr = "%%(advisory)-%(advisory)ds | %%(advisory_type)-%(advisory_type)ds | %%(priority)-%(priority)ds | %%(synopsis)-%(synopsis)ds | %%(affected_channels)s" % maxlen
        print fmtstr % { 'advisory' : 'Advisory', 'advisory_type' : 'Type', 'priority' : 'Priority', 'synopsis' : 'Synopsis', 'affected_channels' : 'Affected Channels (packagecount)'}
        print fmtstr % { 'advisory' : '========', 'advisory_type' : '====', 'priority' : '========', 'synopsis' : '========', 'affected_channels' : '================================'}
    else:
        fmtstr = "%%(advisory)-%(advisory)ds | %%(advisory_type)-%(advisory_type)ds | %%(priority)-%(priority)ds | %%(synopsis)-%(synopsis)ds" % maxlen
        print fmtstr % { 'advisory' : 'Advisory', 'advisory_type' : 'Type', 'priority' : 'Priority', 'synopsis' : 'Synopsis' }
        print fmtstr % { 'advisory' : '========', 'advisory_type' : '====', 'priority' : '========', 'synopsis' : '========' }

    # print fmtstr
    for err in sorted(data, key=itemgetter('priority', 'advisory','synopsis')):
        if err.has_key('chanpkgs'):
            affected_channels = []
            for chan, pkglist in err['chanpkgs'].iteritems():
                label = chandict.get(chan)
                if label in err['channels']:
                    affected_channels.append("%s (%d)" %( label, len(pkglist) ))
            err['affected_channels'] = ', '.join(sorted(affected_channels))

        print fmtstr % err

# ---------------------------------------------------------------------------- #

def main():
    """
    The core script content
    """
    # timestamp for use in filenames (logs, mostly)
    tstamp = time.strftime("%Y-%m-%d.%H%M%S")

    # process command line options and arguments
    opts, args = parse_cmdline(sys.argv[1:])

    try:
        RHN = rhnapi.rhnSession(opts.server,
                                opts.login,
                                opts.password,
                                config=opts.config,
                                savecreds=opts.cache,
                                debug=opts.debug,
                                logfile = opts.logfile,
                                logenable = True,
                                logname = os.path.basename(sys.argv[0]),
                                loglevel=opts.loglevel,
                                )

        if opts.group:
            RHN.logInfo("processing group %s" % opts.group)

        if opts.date:
            monthstart = "%s 00:00:00" % opts.date
            RHN.logInfo("Using date provided on commandline (%s)" % monthstart)
        else:
            monthstart = "%s-01 00:00:00" % time.strftime("%Y-%m")
            RHN.logInfo("No date provided, defaulting to the beginning of this month (%s)" % monthstart)

        if opts.end:
            enddate = "%s 00:00:00" % opts.end
            RHN.logInfo("Using end date provided on commandline (%s)" % enddate)
        else:
            # default to the very end of today
            enddate = "%s 23:59:59" % time.strftime("%Y-%m-%d")
            RHN.logInfo("No end date provided, using %s " % enddate)

        # Default value for sanity
        channelmaps = None
        groupinfo = None

        # find the appropriate channel mapping file
        # process each listed file until one works
        for c in opts.channel_mapping:
            if os.path.isfile(c):
                RHN.logInfo("reading %s" % c)
                if yamlsupport and c.endswith('.yaml'):
                    RHN.logInfo("processing %s" % c)
                    channelmaps = loadYAML(c, RHN.logger)
                else:
                    channelmaps = utils.loadJSON(c)

                if channelmaps is not None:
                    # we've found something!
                    break
            else:
                RHN.logDebug("file %s does not exist, ignoring")

        # now process our channel maps

        if channelmaps is not None:
        # we've successfully parsed the channel mapping file
        # so if we've been asked for a grouplist, do that and exit
            if opts.list:
                dump_mappings(channelmaps)
                sys.exit(0)

            if opts.group:
                if opts.info:
                    dump_mappings(channelmaps, opts.group)
                    sys.exit(0)
                groupinfo= channelmaps.get(opts.group, None)

        else:
            # if not, use the command-line options provided
            if opts.channel and opts.source:
                groupinfo = {
                                'label'    : opts.channel,
                                'source'   : opts.source,
                                'children' : []
                              }
            else:
                RHN.logError("No channel mappings available and source and destination channels not provided. Aborting")
                sys.exit(3)

        # this is only about a single channel structure
        if groupinfo is None:
            if opts.channel and opts.source:
                groupinfo = { 'label'    : opts.channel,
                              'source'   : opts.source,
                              'children' : []
                            }
            else:
                RHN.logError("""Insufficient information provided. Without a group mapping, both channel and source labels are required""")
                sys.exit(2)

        # merge groupinfo into a list of dict, 'label', 'source' keys
        if groupinfo is not None:
            grouplist = [ { 'label' : groupinfo.get('label'), 'source' : groupinfo.get('source') } ]
            for child in groupinfo.get('children'):
                grouplist.append( { 'label' : child.get('label'), 'source' : child.get('source') })
            RHN.logInfo("processing channel group %s" % opts.group)
            results = diff_errata(RHN, grouplist, monthstart, enddate, opts.errtypes, opts.priorities, opts.latest)
        else:
            results = []

        # now we need to write a CSV file, use cvs.DictWriter, it'll be easier :)
        if len(results) > 0:
            # temporary debuggery output
            if opts.json:
                if utils.dumpJSON(results, opts.json):
                    RHN.logInfo("JSON output to %s successful" % opts.json)

            # this should work no matter what
            if opts.output:
                if write_csv(results, opts.output, RHN.logger):
                    RHN.logInfo("CSV output successful")

            header = []
            if opts.group:
                header.append("Errata for %s since %s" %(opts.group, monthstart))
                if opts.errtypes:
                    header.append("Types: %s" % ','.join(opts.errtypes))
                if opts.priorities:
                    header.append("Priorities: %s" % ','.join(opts.priorities))
            if opts.report:
                print ' '.join(header)
                print_report(results, grouplist)
                sys.exit(0)
            else:
                sys.stderr.write("No output file specified, printing CSV to stdout\n")
                if write_csv(results, sys.stdout, RHN.logger):
                    RHN.logInfo("CSV output successful")
        else:
            RHN.logInfo("No Errata to synchronise")




    except KeyboardInterrupt:
        sys.stderr.write("Operation cancelled by keystroke.\n")
        sys.exit(1)

# --------------------------------------------------------------------------------- #

if __name__ == '__main__':
    # if the script is run directly, do this:
    main()

# footer - do not edit below here
# vim: set et cindent ts=4 sts=4 sw=4 ft=python nofen:
